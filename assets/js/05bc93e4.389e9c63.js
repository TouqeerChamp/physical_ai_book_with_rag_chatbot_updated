"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[628],{8453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>l});var a=i(6540);const s={},r=a.createContext(s);function t(e){const n=a.useContext(r);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:t(e.components),a.createElement(r.Provider,{value:n},e.children)}},9536:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>t,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"chapter-04-vision","title":"Chapter 4: Computer Vision","description":"Core Concepts","source":"@site/docs/chapter-04-vision.md","sourceDirName":".","slug":"/chapter-04-vision","permalink":"/physical_ai_book_with_rag_chatbot_updated/chapter-04-vision","draft":false,"unlisted":false,"editUrl":"https://github.com/TouqeerChamp/docs/chapter-04-vision.md","tags":[],"version":"current","frontMatter":{"title":"Chapter 4: Computer Vision","sidebar_label":"4. Computer Vision"},"sidebar":"tutorialSidebar","previous":{"title":"3. ROS 2 Basics","permalink":"/physical_ai_book_with_rag_chatbot_updated/chapter-03-ros2"},"next":{"title":"5. Arm Control","permalink":"/physical_ai_book_with_rag_chatbot_updated/chapter-05-control"}}');var s=i(4848),r=i(8453);const t={title:"Chapter 4: Computer Vision",sidebar_label:"4. Computer Vision"},l="Chapter 4: Computer Vision with RealSense",o={},c=[{value:"Core Concepts",id:"core-concepts",level:2},{value:"<strong>2D vs 3D Vision</strong>",id:"2d-vs-3d-vision",level:3},{value:"Data Pipeline",id:"data-pipeline",level:2},{value:"Installation Guide",id:"installation-guide",level:2},{value:"Installing RealSense Packages",id:"installing-realsense-packages",level:3},{value:"Launching the Camera",id:"launching-the-camera",level:2},{value:"Configuring Rviz for Visualization",id:"configuring-rviz-for-visualization",level:2},{value:"Validation",id:"validation",level:2},{value:"Troubleshooting",id:"troubleshooting",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"chapter-4-computer-vision-with-realsense",children:"Chapter 4: Computer Vision with RealSense"})}),"\n",(0,s.jsx)(n.h2,{id:"core-concepts",children:"Core Concepts"}),"\n",(0,s.jsx)(n.p,{children:"Computer vision is the foundation of robotic perception, enabling robots to interpret and understand their environment. Understanding the difference between 2D and 3D vision is crucial for working with RGB-D cameras like the Intel RealSense."}),"\n",(0,s.jsx)(n.h3,{id:"2d-vs-3d-vision",children:(0,s.jsx)(n.strong,{children:"2D vs 3D Vision"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"2D images"})," consist of individual pixels arranged in a grid, each containing intensity or color values. They represent what a camera sees from a single viewpoint. These images capture appearance and texture but lack depth information."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"3D vision"}),", on the other hand, uses ",(0,s.jsx)(n.strong,{children:"RGB-D cameras"})," to capture both color (RGB) and depth (D) information. The depth data allows the robot to understand spatial relationships, distances, and object volumes. Instead of a 2D grid of pixels, the camera generates a ",(0,s.jsx)(n.strong,{children:"point cloud"})," \u2013 a set of data points in 3D space representing the coordinates (x, y, z) of object surfaces."]}),"\n",(0,s.jsxs)(n.p,{children:["This ",(0,s.jsx)(n.strong,{children:"depth information"})," is critical for robotic perception as it enables:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Obstacle detection and avoidance"}),"\n",(0,s.jsx)(n.li,{children:"Distance measurements"}),"\n",(0,s.jsx)(n.li,{children:"Spatial mapping"}),"\n",(0,s.jsx)(n.li,{children:"Object recognition and manipulation"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"data-pipeline",children:"Data Pipeline"}),"\n",(0,s.jsx)(n.p,{children:"RealSense cameras connect to your robot and publish data to ROS 2 topics, which can then be visualized in Rviz. Here's the flow:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-mermaid",children:"flowchart LR\r\n    A[RealSense Camera] --\x3e B[ROS 2 Driver]\r\n    B --\x3e C[Rviz2]\r\n    style A fill:#8fbc8f\r\n    style B fill:#add8e6\r\n    style C fill:#ffb6c1\n"})}),"\n",(0,s.jsx)(n.h2,{id:"installation-guide",children:"Installation Guide"}),"\n",(0,s.jsx)(n.p,{children:"To get started with the RealSense camera in ROS 2, you'll need to install the required packages."}),"\n",(0,s.jsx)(n.h3,{id:"installing-realsense-packages",children:"Installing RealSense Packages"}),"\n",(0,s.jsx)(n.p,{children:"First, update your package index to ensure you have access to the latest packages:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"sudo apt update\n"})}),"\n",(0,s.jsx)(n.p,{children:"Then install the RealSense2 camera package:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"sudo apt install ros-humble-realsense2-camera\n"})}),"\n",(0,s.jsx)(n.p,{children:"Optionally, install the development packages for advanced features:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"sudo apt install ros-humble-librealsense2-dev\n"})}),"\n",(0,s.jsx)(n.p,{children:"Before launching the camera, check that your RealSense device is properly detected:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"rs-enumerate-devices\n"})}),"\n",(0,s.jsx)(n.p,{children:"This command should list your connected RealSense device. If the device isn't detected, verify the USB connection and check that you have proper permissions to access the device."}),"\n",(0,s.jsx)(n.h2,{id:"launching-the-camera",children:"Launching the Camera"}),"\n",(0,s.jsx)(n.p,{children:"Once the packages are installed, you can launch the RealSense camera driver to begin streaming data:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"ros2 launch realsense2_camera rs_launch.py\n"})}),"\n",(0,s.jsx)(n.p,{children:"To enable depth stream specifically (if not enabled by default):"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"ros2 launch realsense2_camera rs_launch.py enable_depth:=true\n"})}),"\n",(0,s.jsx)(n.p,{children:"For custom configurations, you can specify parameters like resolution:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"ros2 launch realsense2_camera rs_launch.py camera_name:=mycam width:=640 height:=480\n"})}),"\n",(0,s.jsx)(n.h2,{id:"configuring-rviz-for-visualization",children:"Configuring Rviz for Visualization"}),"\n",(0,s.jsx)(n.p,{children:"Now that the camera is streaming data, let's visualize it in Rviz. Follow these steps:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Launch Rviz2 in a new terminal:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"ros2 run rviz2 rviz2\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:'In the Displays panel, click the "Add" button at the bottom.'}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:'In the "Add Display" dialog, select "By topic".'}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Find and add ",(0,s.jsx)(n.code,{children:"/camera/color/image_raw"})," as an Image display."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:'Again click "Add" and select "By topic".'}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Find and add ",(0,s.jsx)(n.code,{children:"/camera/depth/color/points"})," as a PointCloud2 display."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"To improve the visualization of the point cloud:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Expand the PointCloud2 display in the left panel"}),"\n",(0,s.jsx)(n.li,{children:'Change the "Color Transformer" to "RGB8" to visualize colors from the RGB camera'}),"\n",(0,s.jsx)(n.li,{children:'Adjust the "Size (m)" value to change the size of the point cloud visualization'}),"\n",(0,s.jsx)(n.li,{children:'Modify the "Style" to "Points" or "Flat Squares" based on your preference'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"With these configurations, you'll be able to see both the raw color image from the camera and the 3D point cloud data in Rviz."}),"\n",(0,s.jsx)(n.h2,{id:"validation",children:"Validation"}),"\n",(0,s.jsx)(n.p,{children:"To verify that your RealSense camera is properly publishing data, use these commands:"}),"\n",(0,s.jsx)(n.p,{children:"Check that the camera topics are being published:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"ros2 topic list | grep camera\n"})}),"\n",(0,s.jsx)(n.p,{children:"Specifically verify the presence of these key topics:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"/camera/color/image_raw"})," - The raw color image stream"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"/camera/depth/color/points"})," - The 3D point cloud data"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"You can also echo one of the topics to verify data flow:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"ros2 topic echo /camera/color/image_raw --field data | head -n 5\n"})}),"\n",(0,s.jsx)(n.p,{children:"For direct visualization of the image stream, you can use:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"ros2 run image_view image_view --ros-args -p image:=/camera/color/image_raw\n"})}),"\n",(0,s.jsx)(n.p,{children:"Confirm that Rviz is properly displaying both the image and the point cloud data. You should see real-time updates of your environment in both displays."}),"\n",(0,s.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,s.jsx)(n.p,{children:"If you're having issues with the camera:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Ensure the RealSense device is properly connected via USB"}),"\n",(0,s.jsxs)(n.li,{children:["Run ",(0,s.jsx)(n.code,{children:"rs-enumerate-devices"})," to verify the device is detected"]}),"\n",(0,s.jsxs)(n.li,{children:["Make sure you've sourced your ROS 2 environment: ",(0,s.jsx)(n.code,{children:"source /opt/ros/humble/setup.bash"})]}),"\n",(0,s.jsx)(n.li,{children:"Check that you have proper permissions to access the device"}),"\n",(0,s.jsx)(n.li,{children:"Try unplugging and reconnecting the camera"}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}}}]);